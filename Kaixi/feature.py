import pandas as pd
import lightgbm as lgb
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import warnings
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
import os
from datetime import datetime, timedelta
import requests
import sys
import os

# å¿½ç•¥ä¸€äº›å¸¸è§çš„ pandas è­¦å‘Š
warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)

def load_realtime_data():
    """ä»APIè·å–å®æ—¶æ•°æ®å’Œæœ€æ–°çš„DAMä»·æ ¼"""
    print("è·å–å®æ—¶æ•°æ®...")
    
    # 1. è·å–å®æ—¶é¢„æµ‹æ•°æ®
    print("1. è·å–å®æ—¶é¢„æµ‹æ•°æ®...")
    forecast_url = "https://opendata.elia.be/api/explore/v2.1/catalog/datasets/ods161/records"
    r_forecast = requests.get(forecast_url, params={"limit": 20, "order_by": "datetime DESC"}, timeout=10)
    df_forecast = pd.DataFrame(r_forecast.json()["results"])[["datetime", "imbalanceprice"]]
    df_forecast.columns = ["datetime_utc", "price_eur_mwh"]
    df_forecast["datetime_utc"] = pd.to_datetime(df_forecast["datetime_utc"], utc=True)
    df_forecast = df_forecast.set_index('datetime_utc').sort_index()
    
    # 2. è·å–å†å²å®é™…æ•°æ®
    print("2. è·å–å†å²å®é™…æ•°æ®...")
    actual_url = "https://opendata.elia.be/api/explore/v2.1/catalog/datasets/ods134/records"
    r_actual = requests.get(actual_url, params={"limit": 20, "order_by": "datetime DESC"}, timeout=10)
    df_actual = pd.DataFrame(r_actual.json()["results"])[["datetime", "imbalanceprice"]]
    df_actual.columns = ["datetime_utc", "price_eur_mwh"]
    df_actual["datetime_utc"] = pd.to_datetime(df_actual["datetime_utc"], utc=True)
    df_actual = df_actual.set_index('datetime_utc').sort_index()
    
    # 3. è¯»å–æœ€æ–°çš„DAMä»·æ ¼
    print("3. è¯»å–DAMä»·æ ¼æ•°æ®...")
    df_dam = pd.read_csv('data/dam_1028.csv')
    df_dam['datetime_utc'] = pd.to_datetime(df_dam['datetime_utc'])
    df_dam = df_dam.set_index('datetime_utc').sort_index()
    
    # é‡å‘½ååˆ—ä»¥ä¿æŒä¸€è‡´æ€§
    df_forecast = df_forecast.rename(columns={'price_eur_mwh': 'forecast_price'})
    df_actual = df_actual.rename(columns={'price_eur_mwh': 'target_actual_price'})
    df_dam = df_dam.rename(columns={'price_eur_mwh': 'dam_price'})
    return df_forecast, df_actual, df_dam

r = requests.get(
    "https://opendata.elia.be/api/explore/v2.1/catalog/datasets/ods161/records",
    params={"limit": 10, "order_by": "datetime DESC"},
    timeout=10
)
df_forecast = pd.DataFrame(r.json()["results"])[["datetime", "imbalanceprice"]]
df_forecast.columns = ["datetime_utc", "price_eur_mwh"]

df_forecast["datetime_utc"] = pd.to_datetime(df_forecast["datetime_utc"], utc=True)
df_forecast["date"]   = df_forecast["datetime_utc"].dt.date
df_forecast["hour"]   = df_forecast["datetime_utc"].dt.hour
df_forecast["minute"] = df_forecast["datetime_utc"].dt.minute
df_forecast["second"] = df_forecast["datetime_utc"].dt.second

df_forecast = df_forecast[["datetime_utc","date","hour","minute","second","price_eur_mwh"]]

def load_training_data():
    """åŠ è½½è®­ç»ƒç”¨çš„å†å²æ•°æ®ï¼ˆCSVæ–‡ä»¶ï¼‰ã€‚"""
    print("å¼€å§‹åŠ è½½æ•°æ®...")

    # 1. 1åˆ†é’Ÿé—´éš”çš„é¢„æµ‹ä¸å¹³è¡¡ä»·æ ¼ï¼ˆæˆ‘ä»¬çš„ä¸»è¦ç‰¹å¾æ¥æºï¼‰
    df_forecast = pd.read_csv("data/imbalance_forecast.csv")
    if 'datetime_utc' not in df_forecast.columns:
        raise KeyError("ç¼ºå°‘ datetime_utc åˆ—")
    df_forecast['datetime_utc'] = pd.to_datetime(df_forecast['datetime_utc'], errors='coerce', utc=True)
    df_forecast = df_forecast.dropna(subset=['datetime_utc'])
    df_forecast = df_forecast.set_index('datetime_utc').sort_index()
    # é‡å‘½åä»·æ ¼åˆ—ä»¥ä¾¿åŒºåˆ†
    df_forecast = df_forecast.rename(columns={'price_eur_mwh': 'forecast_price'})
    print(f"  - é¢„æµ‹æ•°æ® (forecast) åŠ è½½å®Œæ¯•ï¼Œå½¢æ€: {df_forecast.shape}")

    # 2. 15åˆ†é’Ÿé—´éš”çš„å®é™…ä¸å¹³è¡¡ä»·æ ¼ï¼ˆæˆ‘ä»¬çš„ç›®æ ‡å˜é‡æ¥æºï¼‰
    df_actual = pd.read_csv("data/imbalance_actual.csv")
    if 'datetime_utc' not in df_actual.columns:
        raise KeyError("ç¼ºå°‘ datetime_utc åˆ—")
    df_actual['datetime_utc'] = pd.to_datetime(df_actual['datetime_utc'], errors='coerce', utc=True)
    df_actual = df_actual.dropna(subset=['datetime_utc'])
    df_actual = df_actual.set_index('datetime_utc').sort_index()
    # é‡å‘½åä»·æ ¼åˆ—ä»¥ä¾¿åŒºåˆ†
    df_actual = df_actual.rename(columns={'price_eur_mwh': 'target_actual_price'})
    print(f"  - å®é™…æ•°æ® (actual) åŠ è½½å®Œæ¯•ï¼Œå½¢æ€: {df_actual.shape}")

    # 3. 15åˆ†é’Ÿé—´éš”çš„æ—¥å‰å¸‚åœºä»·æ ¼ï¼ˆä¸€ä¸ªé‡è¦ç‰¹å¾ï¼‰
    df_dam = pd.read_csv('data/dam_prices.csv')
    if 'datetime_utc' not in df_dam.columns:
        raise KeyError("ç¼ºå°‘ datetime_utc åˆ—")
    df_dam['datetime_utc'] = pd.to_datetime(df_dam['datetime_utc'], errors='coerce', utc=True)
    df_dam = df_dam.dropna(subset=['datetime_utc'])
    df_dam = df_dam.set_index('datetime_utc').sort_index()
    df_dam = df_dam.rename(columns={'price_eur_mwh': 'dam_price'})
    print(f"  - æ—¥å‰ä»·æ ¼ (DAM) åŠ è½½å®Œæ¯•ï¼Œå½¢æ€: {df_dam.shape}")

    return df_forecast, df_actual, df_dam


def create_features_and_target(df_forecast, df_actual, df_dam, is_training=True):
    """
    å°†æ•°æ®æ¡†åˆå¹¶ï¼Œåˆ›å»ºç‰¹å¾å’Œç›®æ ‡å˜é‡ã€‚
    ç›®æ ‡ï¼šæ¯åˆ†é’Ÿè¿›è¡Œé¢„æµ‹ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ª15åˆ†é’Ÿçš„å®é™…ä»·æ ¼ã€‚
    """
    print("å¼€å§‹è¿›è¡Œç‰¹å¾å·¥ç¨‹å’Œç›®æ ‡å¯¹é½...")

    # 1. å°†1åˆ†é’Ÿçš„é¢„æµ‹æ•°æ®ä½œä¸ºæˆ‘ä»¬çš„åŸºç¡€æ•°æ®æ¡†
    df = df_forecast.copy()

    # 2. åˆ›å»ºç›®æ ‡å˜é‡ (Y)
    # ç›®æ ‡æ˜¯é¢„æµ‹ *ä¸‹ä¸€ä¸ª* 15åˆ†é’Ÿçš„å®é™…ä»·æ ¼
    # æˆ‘ä»¬å°†æ¯ä¸ª1åˆ†é’Ÿçš„æ—¶é—´æˆ³æ˜ å°„åˆ°å®ƒ *ä¹‹å* çš„é‚£ä¸ª15åˆ†é’Ÿçš„å¼€å§‹æ—¶é—´
    # ä¾‹å¦‚ï¼š14:01 -> 14:15, 14:14 -> 14:15, 14:15 -> 14:30
    df['target_timestamp'] = df.index.floor('15min') + pd.Timedelta('15min')

    # å°†ç›®æ ‡ä»·æ ¼ï¼ˆå®é™…ä»·æ ¼ï¼‰åˆå¹¶èµ·æ¥
    df = pd.merge(
        df,
        df_actual[['target_actual_price']],
        left_on='target_timestamp',
        right_index=True,
        how='left'
    )

    # 3. åˆå¹¶ç‰¹å¾ (X) - æ—¥å‰ (DAM) ä»·æ ¼
    # æˆ‘ä»¬ä½¿ç”¨ merge_asof æ¥è·å–åœ¨å½“å‰1åˆ†é’Ÿæ—¶é—´æˆ³ *ä¹‹å‰* çš„ *æœ€è¿‘* çš„15åˆ†é’ŸDAMä»·æ ¼
    # è¿™èƒ½é˜²æ­¢æ•°æ®æ³„æ¼ï¼ˆå³ä½¿ç”¨æœªæ¥çš„ä¿¡æ¯ï¼‰
    df = pd.merge_asof(
        df.sort_index(),
        df_dam[['dam_price']].sort_index(),
        left_index=True,
        right_index=True,
        direction='backward'  # è·å–ä¹‹å‰æœ€è¿‘çš„å€¼
    )

    # 4. åˆ›å»ºåŸºäºæ—¶é—´çš„ç‰¹å¾
    df['hour'] = df.index.hour
    df['minute'] = df.index.minute
    df['dayofweek'] = df.index.dayofweek
    df['month'] = df.index.month
    df['quarter'] = df.index.quarter
    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)

    # 5. åˆ›å»ºæ»å (Lag) å’Œ æ»šåŠ¨ (Rolling) ç‰¹å¾
    # ä½¿ç”¨1åˆ†é’Ÿé¢„æµ‹ä»·æ ¼æ¥åˆ›å»ºç‰¹å¾
    df['forecast_price_lag_1min'] = df['forecast_price'].shift(1)
    df['forecast_price_lag_15min'] = df['forecast_price'].shift(15)

    # 5åˆ†é’Ÿæ»šåŠ¨å¹³å‡
    df['forecast_rolling_mean_5min'] = df['forecast_price'].rolling(window=5).mean().shift(1)
    # 15åˆ†é’Ÿæ»šåŠ¨æ ‡å‡†å·®ï¼ˆæ³¢åŠ¨æ€§ï¼‰
    df['forecast_rolling_std_15min'] = df['forecast_price'].rolling(window=15).std().shift(1)

    # 6. äº¤äº’ç‰¹å¾
    # é¢„æµ‹ä»·æ ¼ä¸æ—¥å‰ä»·æ ¼çš„å·®å¼‚
    df['forecast_vs_dam'] = df['forecast_price'] - df['dam_price']

    # 7. æ¸…ç†æ•°æ®
    if is_training:
        # è®­ç»ƒæ¨¡å¼ï¼šåˆ é™¤æ‰€æœ‰ç¼ºå¤±å€¼
        df = df.dropna()
    else:
        # é¢„æµ‹æ¨¡å¼ï¼šåªä¿ç•™æœ€åä¸€è¡Œï¼Œå…è®¸ç›®æ ‡å˜é‡ä¸ºç©º
        df = df.tail(1).copy()
        # åªåˆ é™¤ç‰¹å¾ä¸­çš„ç¼ºå¤±å€¼ï¼Œå…è®¸ç›®æ ‡å˜é‡ä¸ºç©º
        feature_cols = [col for col in df.columns if col != 'target_actual_price']
        df = df.dropna(subset=feature_cols)

    print(f"ç‰¹å¾å·¥ç¨‹å®Œæˆã€‚æœ€ç»ˆæ•°æ®é›†å½¢æ€: {df.shape}")

    # å¿«é€Ÿå±•ç¤ºå¤„ç†åæ•°æ®ä»¥ä¾¿æ£€è§†
    print("\n== å¤„ç†åæ•°æ®å¿«ç…§ ==")
    print(f"å½¢çŠ¶: {df.shape}")
    print("\nå‰ 10 è¡Œ:")
    print(df.head(10))
    print("\nå 5 è¡Œ:")
    print(df.tail(5))

    print("\nåˆ—ä¸ç±»å‹:")
    print(df.dtypes)
    print("\næ¯åˆ—ç¼ºå¤±å€¼æ•°é‡:")
    print(df.isna().sum())

    print("\næ•°å€¼åˆ—æè¿°æ€§ç»Ÿè®¡:")
    pd.set_option('display.max_columns', None)  # ensure pandas prints all columns
    pd.set_option('display.max_rows', None)     # show all rows

    print("\nAll columns:")
    # Return the processed dataframe directly without saving to CSV
    return df

def train_model(df):
    """è®­ç»ƒ LightGBM æ¨¡å‹å¹¶è¿”å›æ¨¡å‹å¯¹è±¡ã€‚"""
    
    # å®šä¹‰ç›®æ ‡å’Œç‰¹å¾
    target_col = 'target_actual_price'
    cols_to_drop = ['date', 'second', 'target_timestamp', target_col, 'hour', 'minute']
    features = [col for col in df.columns if col not in cols_to_drop]
    categorical_features = ['dayofweek', 'month', 'quarter', 'is_weekend']
    
    X = df[features]
    y = df[target_col]
    
    # æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²æ•°æ®
    train_size = int(len(X) * 0.7)
    val_size = int(len(X) * 0.85)
    
    X_train, y_train = X.iloc[:train_size], y.iloc[:train_size]
    X_val, y_val = X.iloc[train_size:val_size], y.iloc[train_size:val_size]
    X_test, y_test = X.iloc[val_size:], y.iloc[val_size:]
    
    print(f"æ•°æ®æ‹†åˆ†å®Œæ¯•:")
    print(f"  - è®­ç»ƒé›†: {X_train.shape}")
    print(f"  - éªŒè¯é›†: {X_val.shape}")
    print(f"  - æµ‹è¯•é›†: {X_test.shape}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = lgb.LGBMRegressor(
        objective='mae',
        metric='mae',
        n_estimators=1000,
        learning_rate=0.05,
        n_jobs=-1,
        random_state=42,
        subsample=0.8,
        colsample_bytree=0.8
    )
    
    print("\nå¼€å§‹è®­ç»ƒæ¨¡å‹...")
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric='mae',
        callbacks=[lgb.early_stopping(100, verbose=True)],
        categorical_feature=categorical_features
    )
    
    # è¯„ä¼°æ¨¡å‹
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    print(f"\næµ‹è¯•é›† MAE: {mae:.4f}")
    
    # Return model and features directly without saving
    print("\næ¨¡å‹è®­ç»ƒå®Œæˆ")
    return model, features

    # å®šä¹‰ç›®æ ‡å’Œç‰¹å¾
    target_col = 'target_actual_price'

    # ä» 'date' å’Œ 'second' åˆ—ä¸­ç§»é™¤ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½ä¸æ˜¯æœ‰ç”¨çš„ç‰¹å¾
    # 'target_timestamp' åªæ˜¯ä¸€ä¸ªè¾…åŠ©åˆ—ï¼Œä¹Ÿç§»é™¤
    cols_to_drop = [
        'date', 'second', 'target_timestamp', target_col,
        'hour', 'minute'  # å·²ç»ç”¨ä½œåˆ†ç±»ç‰¹å¾äº†
    ]

    # åœ¨ df.columns ä¸­å­˜åœ¨çš„åˆ—æ‰ä¼šè¢«ç§»é™¤
    features = [col for col in df.columns if col not in cols_to_drop]

    # å®šä¹‰åˆ†ç±»ç‰¹å¾ï¼ŒLGBM å¯ä»¥æ›´å¥½åœ°å¤„ç†å®ƒä»¬
    categorical_features = ['dayofweek', 'month', 'quarter', 'is_weekend']

    # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½æ˜¯LGBMæ”¯æŒçš„ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œdatetimeç´¢å¼•éœ€è¦ç§»é™¤ï¼‰
    # åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çš„ç‰¹å¾éƒ½åº”è¯¥æ˜¯æ•°å€¼å‹æˆ–å·²å®šä¹‰çš„åˆ†ç±»

    X = df[features]
    y = df[target_col]

    # é‡è¦çš„ï¼šæŒ‰æ—¶é—´æ‹†åˆ†æ•°æ®ï¼Œä¸èƒ½éšæœºæ‰“ä¹±ï¼
    # æˆ‘ä»¬ä½¿ç”¨ 70% è®­ç»ƒ, 15% éªŒè¯, 15% æµ‹è¯•

    train_size = int(len(X) * 0.7)
    val_size = int(len(X) * 0.85)

    X_train, y_train = X.iloc[:train_size], y.iloc[:train_size]
    X_val, y_val = X.iloc[train_size:val_size], y.iloc[train_size:val_size]
    X_test, y_test = X.iloc[val_size:], y.iloc[val_size:]

    print(f"æ•°æ®æ‹†åˆ†å®Œæ¯•:")
    print(f"  - è®­ç»ƒé›†: {X_train.shape}")
    print(f"  - éªŒè¯é›†: {X_val.shape}")
    print(f"  - æµ‹è¯•é›†: {X_test.shape}")

    # åˆå§‹åŒ– LightGBM æ¨¡å‹
    # ç›®æ ‡æ˜¯æœ€å°åŒ– MAE (Mean Absolute Error)
    lgb_model = lgb.LGBMRegressor(
        objective='mae',
        metric='mae',
        n_estimators=1000,
        learning_rate=0.05,
        n_jobs=-1,
        random_state=42,
        subsample=0.8,
        colsample_bytree=0.8
    )

    print("\nå¼€å§‹è®­ç»ƒæ¨¡å‹...")

    # è®­ç»ƒæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ—©æœŸåœæ­¢
    # è¿™å¯ä»¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œå¹¶åœ¨éªŒè¯é›†MAEä¸å†æ”¹å–„æ—¶åœæ­¢è®­ç»ƒ
    lgb_model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        eval_metric='mae',
        callbacks=[lgb.early_stopping(100, verbose=True)],
        categorical_feature=categorical_features
    )

    print("æ¨¡å‹è®­ç»ƒå®Œæ¯•ã€‚")

    return lgb_model, X_test, y_test, features


def send_prediction_email(current_price, predicted_price, recipient_email="kaixi.yao@outlook.com"):
    """å‘é€é¢„æµ‹ç»“æœé‚®ä»¶"""
    # é‚®ä»¶é…ç½®
    smtp_server = "smtp.mail.yahoo.com"
    smtp_port = 587
    sender_email = "yao_philip@yahoo.com"  # æ›¿æ¢ä¸ºæ‚¨çš„ Outlook é‚®ç®±
    app_password = "ulirkiciqhnrilet"  # æ›¿æ¢ä¸ºæ‚¨çš„åº”ç”¨ä¸“ç”¨å¯†ç 

    try:
        # è®¡ç®—ä»·æ ¼å˜åŒ–
        price_change = predicted_price - current_price
        price_change_pct = (price_change / current_price) * 100 if current_price != 0 else 0
        
        # è·å–æ—¶é—´
        current_time = datetime.now()
        next_quarter = current_time + timedelta(minutes=(15 - current_time.minute % 15))
        
        # åˆ›å»ºé‚®ä»¶
        msg = MIMEMultipart()
        msg['Subject'] = f'NOX Energy - ä»·æ ¼é¢„æµ‹æ›´æ–° ({next_quarter.strftime("%H:%M")} UTC)'
        msg['From'] = sender_email
        msg['To'] = recipient_email
        
        # é‚®ä»¶æ­£æ–‡
        body = f"""NOX Energy ä¸å¹³è¡¡ç”µä»·é¢„æµ‹

é¢„æµ‹ç”Ÿæˆæ—¶é—´: {current_time.strftime('%Y-%m-%d %H:%M:%S')} UTC
é¢„æµ‹ç›®æ ‡æ—¶æ®µ: {next_quarter.strftime('%H:%M')} - {(next_quarter + timedelta(minutes=15)).strftime('%H:%M')} UTC
é¢„æµ‹ä»·æ ¼: {predicted_price:.2f} EUR/MWh
"""
        msg.attach(MIMEText(body, 'plain'))
        
        # Create prediction DataFrame and convert directly to CSV string
        df_prediction = pd.DataFrame({
            'timestamp': [current_time, next_quarter],
            'price_type': ['å½“å‰ä»·æ ¼', 'é¢„æµ‹ä»·æ ¼'],
            'price_eur_mwh': [current_price, predicted_price]
        })
        
        # Convert DataFrame to CSV string in memory
        csv_string = df_prediction.to_csv(index=False, encoding='utf-8')
        
        # Attach CSV string directly to email
        part = MIMEApplication(csv_string.encode('utf-8'), _subtype="csv")
        part.add_header('Content-Disposition', 'attachment', filename="price_prediction.csv")
        msg.attach(part)

        # è¿æ¥åˆ°SMTPæœåŠ¡å™¨å¹¶å‘é€é‚®ä»¶
        server = smtplib.SMTP(smtp_server, smtp_port)
        server.starttls()  # å¯ç”¨TLSåŠ å¯†
        server.login(sender_email, app_password)
        server.send_message(msg)
        server.quit()
        print(f"âœ“ é¢„æµ‹æŠ¥å‘Šå·²å‘é€è‡³ {recipient_email}")
        
        # Log prediction to console instead of file
        print("é¢„æµ‹æ—¥å¿—:")
        print(body)
        print("="*50)
        
    except Exception as e:
        print(f"å‘é€é‚®ä»¶å¤±è´¥: {str(e)}")
        if isinstance(e, smtplib.SMTPAuthenticationError):
            print("è®¤è¯å¤±è´¥ã€‚è¯·æ£€æŸ¥é‚®ç®±å’Œåº”ç”¨å¯†ç ã€‚")
        elif isinstance(e, smtplib.SMTPServerDisconnected):
            print("æœåŠ¡å™¨è¿æ¥æ–­å¼€ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚")

def predict_with_model(df_forecast, df_actual, df_dam, model, features):
    """ä½¿ç”¨æä¾›çš„æ¨¡å‹å¯¹å®æ—¶æ•°æ®è¿›è¡Œé¢„æµ‹"""
    if model is None or features is None:
        raise ValueError("æœªæä¾›æ¨¡å‹æˆ–ç‰¹å¾åˆ—è¡¨")
    
    # å¤„ç†å®æ—¶æ•°æ®
    df = create_features_and_target(df_forecast, df_actual, df_dam, is_training=False)
    
    if df.empty:
        raise ValueError("å¤„ç†åçš„ç‰¹å¾æ•°æ®ä¸ºç©º")
    
    # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„ç‰¹å¾éƒ½å­˜åœ¨
    for feature in features:
        if feature not in df.columns:
            raise ValueError(f"ç¼ºå°‘ç‰¹å¾: {feature}")
    
    # è·å–æœ€æ–°æ—¶é—´ç‚¹çš„ç‰¹å¾
    X_pred = df[features].tail(1)
    
    # è¿›è¡Œé¢„æµ‹
    y_pred = model.predict(X_pred)
    
    prediction_time = X_pred.index[0]
    target_time = prediction_time + pd.Timedelta(minutes=(15 - prediction_time.minute % 15))
    
    result = {
        'prediction_time': prediction_time,
        'target_time': target_time,
        'current_price': df_forecast['forecast_price'].iloc[-1],
        'predicted_price': y_pred[0]
    }
    
    return result

def evaluate_and_predict(model, X_test, y_test, feature_names):
    """åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹å¹¶è¯„ä¼°æ¨¡å‹ã€‚"""

    print("\nåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹...")
    y_pred = model.predict(X_test)

    # è®¡ç®— MAE
    mae = mean_absolute_error(y_test, y_pred)
    print(f"\n======================================")
    print(f"æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„ MAE: {mae:.4f}")
    print(f"======================================")

    # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§
    print("\næ˜¾ç¤ºç‰¹å¾é‡è¦æ€§...")
    lgb.plot_importance(model, max_num_features=20, figsize=(10, 8), importance_type='gain')
    plt.title("LightGBM importance of feature (based on gain)")
    plt.tight_layout()
    plt.show()

    # (å¯é€‰) ç»˜åˆ¶é¢„æµ‹å€¼ vs å®é™…å€¼
    plt.figure(figsize=(15, 6))
    plt.plot(y_test.index, y_test, label='Actual Price', alpha=0.7)
    plt.plot(y_test.index, y_pred, label='Predicted Price', linestyle='--', alpha=0.7)
    plt.legend()
    plt.title(f"Real values from test set vs prediction values (MAE: {mae:.4f})")
    plt.xlabel("time")
    plt.ylabel("price (EUR/MWh)")
    plt.show()


if __name__ == "__main__":
    print("ğŸ”‹ NOX Energy Imbalance Price Prediction ğŸ”‹")
    print("=========================================")
    current_time = datetime.now()
    print(f"å½“å‰æ—¶é—´ (UTC): {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("=========================================\n")
    
    try:
        # åŠ è½½è®­ç»ƒæ•°æ®å¹¶è®­ç»ƒæ–°æ¨¡å‹
        print("\n1. åŠ è½½è®­ç»ƒæ•°æ®...")
        df_forecast, df_actual, df_dam = load_training_data()
        df_processed = create_features_and_target(df_forecast, df_actual, df_dam)
        
        if not df_processed.empty:
            print("\n2. è®­ç»ƒæ¨¡å‹...")
            model, features = train_model(df_processed)
            print("âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
        else:
            raise ValueError("å¤„ç†åçš„è®­ç»ƒæ•°æ®ä¸ºç©º")
        
        # è·å–å®æ—¶é¢„æµ‹
        print("\nè·å–å®æ—¶é¢„æµ‹...")
        print("1. åŠ è½½å®æ—¶æ•°æ®...")
        rt_forecast, rt_actual, rt_dam = load_realtime_data()
        
        print("\n2. ä½¿ç”¨æ¨¡å‹é¢„æµ‹...")
        result = predict_with_model(rt_forecast, rt_actual, rt_dam, model, features)
        
        print("\n=== é¢„æµ‹ç»“æœ ===")
        print(f"é¢„æµ‹æ—¶é—´: {result['prediction_time'].strftime('%Y-%m-%d %H:%M:%S')} UTC")
        print(f"ç›®æ ‡æ—¶é—´: {result['target_time'].strftime('%Y-%m-%d %H:%M:%S')} UTC")
        print(f"é¢„æµ‹ä»·æ ¼: {result['predicted_price']:.2f} EUR/MWh")
        
        # å‘é€é‚®ä»¶é€šçŸ¥
        print("\n3. å‘é€é¢„æµ‹ç»“æœé‚®ä»¶...")
        send_prediction_email(result['current_price'], result['predicted_price'])
        
    except Exception as e:
        print(f"\nå‘ç”Ÿé”™è¯¯:")
        print(f"è¯¦æƒ…: {str(e)}")
    finally:
        print("\nå¤„ç†ç»“æŸã€‚")
